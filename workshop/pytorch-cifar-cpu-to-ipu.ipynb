{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The workshop demo!\n",
    "\n",
    "We will convert this file from being an ordinary PyTorch code that runs on the host cpu to being one that runs on the Graphcore accelerator, the 'ipu'.\n",
    "\n",
    "For conversion, we shall follow the comments marked with \"#DEMO\". These are instructions to insert and delete, and some general chat. The actual lines to insert begin \"#I.\n",
    "\n",
    "However, before doing the conversion, we shall run it on the CPU!\n",
    "\n",
    "#DEMO: This is an original - make a working copy!  \n",
    "#DEMO: DELETE next line - we are headed for the IPU  \n",
    "This runs on the CPU without using the IPU accelerator\n",
    "\n",
    "The main code is taken from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html and is covered by the licence in the correspondig Githib repository, reproduced the accomanying file here, PYTORCH_EXAMPLES_LIBRARY.\n",
    "\n",
    "#DEMO: and \"insert\" this line, i.e. delete the #I characters to make the line official  \n",
    "#I This file has been modified following the instructions at [Pytorch to Poptorch](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/pytorch_to_poptorch.html?highlight=pytorch%20to%20poptorch) ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO: I have added some time taken recording \n",
    "import time\n",
    "event_times = [(\"Start\", time.time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO: Make sure that tke kernel selected is the one from the python environment you created\n",
    "import torch\n",
    "#DEMO: \"poptorch\" is Graphcore's verison of pytorch - it uses their \"poplar\" library.\n",
    "#DEMO: INSERT this line:\n",
    "#I import poptorch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#DEMO: this records the time of our first milestone\n",
    "event_times.append((\"Torch imports done\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#DEMO: Poptorch has its own configration options - this one is for an optimisation\n",
    "#DEMO: Insert these lines:\n",
    "#I opts = poptorch.Options()\n",
    "#I devIterations = 10\n",
    "#I opts.deviceIterations(devIterations)  # ??? what does this do - we shall come back to it\n",
    "\n",
    "#DEMO: Poptorch has its own data loader - ??? how is it different\n",
    "#DEMO: Delete this line\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "#I trainloader = poptorch.DataLoader(options=opts, dataset=trainset, batch_size=batch_size,\n",
    "#I                                           shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "#DEMO: again use Poptorch's dataloader\n",
    "#DEMO: delete this line\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "#I testloader = poptorch.DataLoader(options=opts, dataset=testset, batch_size=batch_size,\n",
    "#I                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "event_times.append((\"Data loaders created\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO: This plots some of the downloaded images, and is unchanged.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "event_times.append((\"Training batch displayed\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#DEMO: this is the original model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x  # This model has no final max - see below - loss crtierion is CrossEntropy so inlcudes a SoftMax and prediction uses max\n",
    "\n",
    "#DEMO: but we are going to wrap that model to tweak the output of the forward() function\n",
    "#DEMO: Delete this line - the variable net will be set, as altered below, to the wrapped version  \n",
    "net = Net()\n",
    "\n",
    "event_times.append((\"Base model declared\", time.time()))\n",
    "\n",
    "#DEMO: Insert this wrapper, and note the difference in output between training and inference stages\n",
    "#I class PoptorchNet(nn.Module):\n",
    "#I     def __init__(self):\n",
    "#I         super().__init__()\n",
    "#I         self.model = Net()\n",
    "#I     \n",
    "#I     def forward(self, input, target=None):  # No target when evaluating\n",
    "#I         out = self.model(input)\n",
    "#I         # https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/pytorch_to_poptorch.html?highlight=pytorch%20to%20poptorch#training\n",
    "#I         # adds a target parameter\n",
    "#I         # also compare https://docs.graphcore.ai/projects/tutorials/en/latest/pytorch/basics/README.html#build-the-model\n",
    "#I         if self.training:\n",
    "#I             return (torch.nn.functional.softmax(out),\n",
    "#I                     torch.nn.CrossEntropyLoss(reduction=\"mean\")(out, target))\n",
    "#I         return out  # because prediction below uses a max on this output\n",
    "#I     \n",
    "#I net = PoptorchNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO: We use the original optimizer functions\n",
    "import torch.optim as optim\n",
    "\n",
    "#DEMO: Delete the next line - because it is now specified in the model wrapper\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "event_times.append((\"Optimzer declared\", time.time()))\n",
    "\n",
    "#DEMO: Wrap it again - wht two steps? maybe partly inference does not need an optimizer\n",
    "#DEMO: INSERT This line for the 2nd wrapping\n",
    "#I poptorch_model = poptorch.trainingModel(net, options=opts, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        #DEMO: For what popTorch.trainingModel does for you in the training loop\n",
    "        #DEMO: see https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/pytorch_to_poptorch.html?highlight=pytorch#the-training-loop\n",
    "        # zero the parameter gradients\n",
    "        #DEMO: delete next line it gets done in the __call__ to the model\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #DEMO: a more complex call to the training model - so delete the next line\n",
    "        outputs = net(inputs)\n",
    "        #DEMO: and INSERT this line:\n",
    "        #I outputs, loss = poptorch_model(inputs,labels)\n",
    "        #DEMO: and DELETE the next three lines, because they are included in the training model __call__\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #DEMO: as small addjustment here to deal with effect of devIternations optimization parameter\n",
    "        #DEMO: DELETE next line\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #DEMO: and replace with:\n",
    "        #I if i % 2000 == 2000 - devIterations * batch_size:    # print every 2000 mini-batches      \n",
    "            print(f'[{epoch + 1}, {(i + 1) * batch_size:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "            event_times.append((f'Epoch {epoch + 1}, Image {(i + 1) * batch_size:5d} trained', time.time()))\n",
    "\n",
    "print('Finished Training')\n",
    "#DEMO: identify major part of training (in this case)\n",
    "#DEM): DELETE the next line\n",
    "event_times.append((\"Training complete\", time.time()))\n",
    "#DEMO: and replace with:\n",
    "#I event_times.append((\"Training complete (inluding complilation)\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model \n",
    "#DEMO: save the model to a diffent file. So DELETE next line and insert the one after that\n",
    "PATH = './cifar_net.pth'\n",
    "#I PATH = './cifar_net_graphcore.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "event_times.append((\"Model saved\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "event_times.append((\"Test batch displayed\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "#DEMO: allow for wrqpping, DELETE the next to lines\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "#DEMO and replace with\n",
    "#I poptorchNet = PoptorchNet()\n",
    "#I inferenceNet = poptorch.inferenceModel(poptorchNet)  \n",
    "#I inferenceNet.load_state_dict(torch.load(PATH))\n",
    "#I inferenceNet.eval()\n",
    "event_times.append((\"Model loaded\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO: more of the same, delete the next line\n",
    "outputs = net(images)\n",
    "#DEMO and replace with \n",
    "#I outputs = inferenceNet(images)\n",
    "\n",
    "#DEMO describe the content of the period more accurately, so DELETE the next line\n",
    "event_times.append((\"Test images evaluated\", time.time()))\n",
    "#DEMO and replace\n",
    "#I event_times.append((\"Test images evaluated (including compilation)\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))\n",
    "event_times.append((\"Test image classes displayed\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        #DEMO more allowing for the wrapping and new variable name, delete the next line\n",
    "        outputs = net(images)\n",
    "        #DEMO and replace with\n",
    "        #I outputs = inferenceNet(images)\n",
    "        \n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "event_times.append((\"Test image class accuracy\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        #DEMO more allowing for the wrapping and new variable name, delete the next line\n",
    "        outputs = net(images)\n",
    "        #DEMO and replace with\n",
    "        #I outputs = inferenceNet(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "event_times.append((\"Test image accuracy by class\", time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "event_times = [(label, event_time - event_times[0][1]) for label, event_time in event_times]\n",
    "\n",
    "#DEMO save the IPU results in theor own file, so DELETE the next line\n",
    "with open(\"times_cpu.json\", \"w\") as f:\n",
    "#DEMO and replace with:\n",
    "#I with open(\"times_ipu_deviter{}.json\".format(devIterations), \"w\") as f:\n",
    "    json.dump(event_times, f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "labels, times = list(zip(*event_times))\n",
    "x = times\n",
    "y = list(range(len(labels)))\n",
    "\n",
    "plt.plot(x, y)\n",
    "#DEMO update title - it's now th IPU, so DELETE the next line\n",
    "plt.title(\"Event progression (snake) - CPU\")\n",
    "#DEMO and replace with:\n",
    "#I plt.title(\"Event progression (snake) - IPU\")\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('Event progression')\n",
    "plt.yticks(ticks=y, labels=labels)\n",
    "plt.show()\n",
    "\n",
    "#DEMO: More detailed information on converting existing codes\n",
    "#DEMO: https://docs.graphcore.ai/projects/differences-ipu-gpu/en/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
